{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b11bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df48caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bimapras/MusicSeparation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow==2.17 numpy musdb librosa soundfile\n",
    "%pip install numpy musdb librosa soundfile # tensorflow 2.19 still compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MusicSeparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from IPython.display import display, Audio\n",
    "from utils import read_audio, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inference expect model with input shape (time, 2)\n",
    "Make sure segment_length is your time length input model (Default model use 88064)\n",
    "Use GPU & Keras Format for faster inference\n",
    "'''\n",
    "\n",
    "reader = read_audio.AudioReader()\n",
    "audio_data, samplerate = reader.read(r'sample/Pierce The Veil - So Far So Fake (Visualizer).mp4')\n",
    "# change path to your upload audio file\n",
    "\n",
    "keras_model_path = r'models/DPTCN.keras'\n",
    "tflite_model_path = r'models/DPTCN.tflite'\n",
    "\n",
    "inference = inference.AudioInference(model=tflite_model_path,\n",
    "                            is_tflite=True,\n",
    "                            segment_length=88064,\n",
    "                            overlap=0.5,\n",
    "                            batch_size=4,\n",
    "                            use_wiener=True,\n",
    "                            stft_frame_length=4096,\n",
    "                            stft_frame_step=1024,\n",
    "                            wiener_iterations=3)\n",
    "pred = inference.predict(audio_data[:44100*20],\n",
    "                        segment_length_sec=30,\n",
    "                        export=True,\n",
    "                        export_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "display(Audio(pred[:, 0, :].numpy().T, rate = SR))\n",
    "display(Audio(pred[:, 1, :].numpy().T, rate = SR))\n",
    "display(Audio(pred[:, 2, :].numpy().T, rate = SR))\n",
    "display(Audio(pred[:, 3, :].numpy().T, rate = SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f82b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "stems = ['Vocals', 'Drums', 'Bass', 'Other']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    audio_segment = pred[:, i, :].numpy()\n",
    "\n",
    "    # Convert stereo to mono for spectrogram calculation\n",
    "    if audio_segment.shape[1] == 2:\n",
    "        audio_segment = np.mean(audio_segment, axis=1)\n",
    "\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_segment)), ref=np.max)\n",
    "\n",
    "    img = librosa.display.specshow(D, sr=samplerate, x_axis='time', y_axis='log', ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Spectrogram of {stems[i]}')\n",
    "    fig.colorbar(img, ax=axes[row, col], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src_separation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
